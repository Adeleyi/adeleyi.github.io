---
---

%%%%%% Pre-Print %%%%%%

@article{zhan2025spri,
    title={SPRI: Aligning Large Language Models with Context-Situated Principles},
    author={Hongli Zhan and Muneeza Azmat and Raya Horesh and Junyi Jessy Li and Mikhail Yurochkin},
    year={2025},
        abbr={arXiv 2025},
        abstract={Aligning Large Language Models to integrate and reflect human values, especially for tasks that demand intricate human oversight, is arduous since it is resource-intensive and time-consuming to depend on human expertise for context-specific guidance. Prior work has utilized predefined sets of rules or principles to steer the behavior of models (Bai et al., 2022; Sun et al., 2023). However, these principles tend to be generic, making it challenging to adapt them to each individual input query or context. In this work, we present Situated-PRInciples (SPRI), a framework requiring minimal or no human effort that is designed to automatically generate guiding principles in real-time for each input query and utilize them to align each response. We evaluate SPRI on three tasks, and show that 1) SPRI can derive principles in a complex domain-specific task that leads to on-par performance as expert-crafted ones; 2) SPRI-generated principles lead to instance-specific rubrics that outperform prior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data leads to substantial improvement on truthfulness. We release our code and model generations at https://github.com/honglizhan/SPRI-public.},
        link={https://arxiv.org/abs/2502.03397},
        pdf={2502.03397v1.pdf},
        code={https://github.com/honglizhan/SPRI-public},
        note={Under review},
        selected={true}
}

%%%%%% Reviewed %%%%%%

@inproceedings{zhan2024large,
    title={Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided},
    author={Hongli Zhan and Allen Zheng and Yoon Kyung Lee and Jina Suh and Junyi Jessy Li and Desmond Ong},
    year={2024},
    booktitle={Proceedings of the First Conference on Language Modeling},
        abbr={COLM 2024},
        abstract={Large language models (LLMs) have offered new opportunities for emotional support, and recent work has shown that they can produce empathic responses to people in distress. However, long-term mental well-being requires emotional self-regulation, where a one-time empathic response falls short. This work takes a first step by engaging with cognitive reappraisals, a strategy from psychology practitioners that uses language to targetedly change negative appraisals that an individual makes of the situation; such appraisals is known to sit at the root of human emotional experience. We hypothesize that psychologically grounded principles could enable such advanced psychology capabilities in LLMs, and design RESORT which consists of a series of reappraisal constitutions across multiple dimensions that can be used as LLM instructions. We conduct a first-of-its-kind expert evaluation (by clinical psychologists with M.S. or Ph.D. degrees) of an LLM's zero-shot ability to generate cognitive reappraisal responses to medium-length social media messages asking for support. This fine-grained evaluation showed that even LLMs at the 7B scale guided by RESORT are capable of generating empathic responses that can help users reappraise their situations.},
        link={https://arxiv.org/abs/2404.01288},
        pdf={2024.colm.821.pdf},
        code={https://github.com/honglizhan/RESORT_cognitive_reappraisal},
        open_review={https://openreview.net/forum?id=yK8MT91dQY},
        note={28.8% acceptance rate (299 out of 1,036 submissions)},
        poster={2024.colm.821.poster.pdf},
        selected={true},
}

@inproceedings{lee2024large,
    title={Large Language Models Produce Responses Perceived to be Empathic},
    author={Yoon Kyung Lee and Jina Suh and Hongli Zhan and Junyi Jessy Li and Desmond C. Ong},
    year={2024},
    booktitle={Proceedings of the 12th International Conference on Affective Computing and Intelligent Interaction},
        abbr={ACII 2024},
        abstract={Large Language Models (LLMs) have demonstrated surprising performance on many tasks, including writing supportive messages that display empathy. Here, we had these models generate empathic messages in response to posts describing common life experiences, such as workplace situations, parenting, relationships, and other anxiety- and anger-eliciting situations. Across two studies (N=192, 202), we showed human raters a variety of responses written by several models (GPT4 Turbo, Llama2, and Mistral), and had people rate these responses on how empathic they seemed to be. We found that LLM-generated responses were consistently rated as more empathic than human-written responses. Linguistic analyses also show that these models write in distinct, predictable "styles", in terms of their use of punctuation, emojis, and certain words. These results highlight the potential of using LLMs to enhance human peer support in contexts where empathy is important.},
        link={https://arxiv.org/abs/2403.18148},
        pdf={2403.18148v1.pdf},
        code={https://github.com/yoonlee78/LLM_empathy_social_support},
        note={The acceptance rate was lower than 40%},
}

@inproceedings{zhan-etal-2023-evaluating,
    title={Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models},
    author={Hongli Zhan and Desmond C. Ong and Junyi Jessy Li},
    booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
    month={dec},
    year={2023},
    address={Singapore},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.findings-emnlp.962},
    pages={14418--14446},
        abbr={EMNLP 2023},
        abstract={The emotions we experience involve complex processes; besides physiological aspects, research in psychology has studied cognitive appraisals where people assess their situations subjectively, according to their own values (Scherer, 2005). Thus, the same situation can often result in different emotional experiences. While the detection of emotion is a well-established task, there is very limited work so far on the automatic prediction of cognitive appraisals. This work fills the gap by presenting CovidET-Appraisals, the most comprehensive dataset to-date that assesses 24 appraisal dimensions, each with a natural language rationale, across 241 Reddit posts. CovidET-Appraisals presents an ideal testbed to evaluate the ability of large language models {---} excelling at a wide range of NLP tasks {---} to automatically assess and explain cognitive appraisals. We found that while the best models are performant, open-sourced LLMs fall short at this task, presenting a new challenge in the future development of emotionally intelligent models. We release our dataset at https://github.com/honglizhan/CovidET-Appraisals-Public.},
        award={Findings},
        link={https://aclanthology.org/2023.findings-emnlp.962/},
        pdf={2023.findings-emnlp.962.pdf},
        code={https://github.com/honglizhan/CovidET-Appraisals-Public},
        open_review={https://openreview.net/forum?id=68A4GE4nqf},
        note={45.4% acceptance rate (1,758 out of 3,868 submissions)},
        selected={true},
}

@inproceedings{sosea-etal-2023-unsupervised,
    title={Unsupervised Extractive Summarization of Emotion Triggers},
    author={Sosea*, Tiberiu  and  Zhan*, Hongli  and Li, Junyi Jessy  and Caragea, Cornelia},
    booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month={jul},
    year={2023},
    address={Toronto, Canada},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.acl-long.531},
    pages={9550--9569},
        abbr={ACL 2023},
        award={Main},
        abstract={Understanding what leads to emotions during large-scale crises is important as it can provide groundings for expressed emotions and subsequently improve the understanding of ongoing disasters. Recent approaches trained supervised models to both detect emotions and explain emotion triggers (events and appraisals) via abstractive summarization. However, obtaining timely and qualitative abstractive summaries is expensive and extremely time-consuming, requiring highly-trained expert annotators. In time-sensitive, high-stake contexts, this can block necessary responses. We instead pursue unsupervised systems that extract triggers from text. First, we introduce CovidET-EXT, augmenting (Zhan et al., 2022){'}s abstractive dataset (in the context of the COVID-19 crisis) with extractive triggers. Second, we develop new unsupervised learning models that can jointly detect emotions and summarize their triggers. Our best approach, entitled Emotion-Aware Pagerank, incorporates emotion information from external sources combined with a language understanding module, and outperforms strong baselines. We release our data and code at https://github.com/tsosea2/CovidET-EXT.},
        link={https://aclanthology.org/2023.acl-long.531/},
        pdf={2023.acl-long.531.pdf},
        code={https://github.com/tsosea2/CovidET-EXT},
        poster={2023.acl-long.531.poster.pdf},
        slides={2023.acl-long.531.slides.pdf},
        note={23.5% acceptance rate (910 out of 3,872 submissions)},
        selected={true},
}

@inproceedings{zhan-etal-2022-feel,
    title={Why Do You Feel This Way? Summarizing Triggers of Emotions in Social Media Posts},
    author={Zhan*, Hongli  and Sosea*, Tiberiu  and Caragea, Cornelia  and Li, Junyi Jessy},
    booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    month={dec},
    year={2022},
    address={Abu Dhabi, United Arab Emirates},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.emnlp-main.642},
    pages={9436--9453},
        abbr={EMNLP 2022},
        award={Main},
        abstract={Crises such as the COVID-19 pandemic continuously threaten our world and emotionally affect billions of people worldwide in distinct ways. Understanding the triggers leading to people{'}s emotions is of crucial importance. Social media posts can be a good source of such analysis, yet these texts tend to be charged with multiple emotions, with triggers scattering across multiple sentences. This paper takes a novel angle, namely, emotion detection and trigger summarization, aiming to both detect perceived emotions in text, and summarize events and their appraisals that trigger each emotion. To support this goal, we introduce CovidET (Emotions and their Triggers during Covid-19), a dataset of {\textasciitilde}1,900 English Reddit posts related to COVID-19, which contains manual annotations of perceived emotions and abstractive summaries of their triggers described in the post. We develop strong baselines to jointly detect emotions and summarize emotion triggers. Our analyses show that CovidET presents new challenges in emotion-specific summarization, as well as multi-emotion detection in long social media posts.},
        link={https://aclanthology.org/2022.emnlp-main.642/},
        pdf={2022.emnlp-main.642.pdf},
        code={https://github.com/honglizhan/CovidET},
        video={https://www.youtube.com/watch?v=qjBmgeGJmtM&t=17s&ab_channel=HongliZhan},
        poster={2022.emnlp-main.642.poster.pdf},
        slides={2022.emnlp-main.642.slides.pdf},
        note={22.1% acceptance rate (715 out of 3,242 submissions)},
        selected={true},
}
